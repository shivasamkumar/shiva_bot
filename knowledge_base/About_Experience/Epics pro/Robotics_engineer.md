# Robotics Engineer

**Employer:** EPICS Pro, Arizona State University  
**Clients:** IT core Foundation, Rainier Labs
**Dates Employed:** July 2024 â€“ July 2025  

## Key Responsibilities & Achievements
- Collaborated on AGV development to architect and implement the perception and navigation stack, integrating LiDAR and vision sensors for SLAM-driven localization (achieving <5 cm RMSE) and reducing trajectory computation latency by 30%.  
- Built a Kalman filter in ROS 2 to fuse LiDAR (Velodyne VLP-16) and RealSense D455 data for 97% detection accuracy, and created a digital twin in NVIDIA Isaac Sim for AGV path planning, reducing real-world testing costs by 40%.  
- Programmed ABB IRB 2600 robotic arms using ROS-I and MoveIt to automate palletizing tasks for a manufacturing client, reducing cycle time by 25% through EtherCAT integration with Beckhoff PLCs.  
- Optimized CHOMP and STOMP planners in MoveIt for 7-DOF manipulators, reducing motion jerk by 30%, boosting grasp success by 30%, and cutting execution time by 25% for autonomous voice-controlled pick-and-place via a Flask-based interface.  
- Deployed a YOLO v12-based vision detector on an autonomous agricultural rover, achieving 98% crop disease detection accuracy at 25 FPS and cutting field survey time by 60%; launched a RAG-powered chat app built with LangChain on a web server with 99.9% uptime supporting daily active users.  
- Implemented visual-language architectures, large language models, and convolutional neural networks (CNNs) for natural-language-based decision-making, streamlining tasks and reducing execution time by 25% while improving precision.  
- Prototyped lightweight UAV frames in carbon-fiber PETG on an Ultimaker S5 using CATIA V5, reducing frame weight by 25%, and validated designs via Ansys Static Structural for 5G load tolerance.  
- Developed an autonomous UAV for surveillance, integrating ORB-SLAM and sensor fusion for real-time localization and mapping using ROS 2 and Gazebo; utilized Python and OpenCV for live image processing to enhance situational awareness.  
- Programmed PX4 autopilot firmware for hexacopter UAVs, integrating MAVLink with ROS 2 for swarm coordination in agricultural monitoring missions, achieving 95% mission success in GPS-denied environments.

## Skills & Expertise
- Sensor fusion & state estimation (Kalman filters, SLAM)  
- Autonomous navigation & motion planning (CHOMP, STOMP)  
- Perception pipelines (LiDAR, RealSense, YOLO v12)  
- Control systems & robotic arm automation  
- Algorithm optimization & real-time performance tuning  
- Natural-language-driven decision making & RAG  
- UAV design, prototyping, and swarm coordination  
- Cross-functional collaboration & rapid prototyping  

## Tools & Frameworks Used
- **Middleware & Simulation:** ROS 2, ROS-I, MoveIt, Gazebo, NVIDIA Isaac Sim  
- **Languages & Libraries:** Python, C++, OpenCV  
- **Perception & AI:** YOLO v12, LangChain, large-language models, CNNs  
- **Communication & Integration:** EtherCAT, MAVLink, PX4 Autopilot  
- **Design & Validation:** CATIA V5, Ansys Static Structural  
- **Web & Interface:** Flask (voice-control interface)  
